{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhWV8oes-wKR"
   },
   "source": [
    "# COURSE: A deep understanding of deep learning\n",
    "## SECTION: Data matrices and loaders\n",
    "### LECTURE: Anatomy of a torch dataset and dataloader\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com\n",
    "##### COURSE URL: udemy.com/course/deeplearning_x/?couponCode=202401\n",
    "##### Modified from original code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YeuAheYyhdZw"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader,TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFv_cmvApLb0"
   },
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "aykKFgznOako"
   },
   "outputs": [],
   "source": [
    "# create some data in numpy\n",
    "\n",
    "nObservations = 100\n",
    "nFeatures = 20\n",
    "\n",
    "data = np.random.randn(nObservations,nFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Y_tZ1ymVp0Sf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy data:\n",
      "<class 'numpy.ndarray'>\n",
      "(100, 20)\n",
      "float64\n",
      " \n",
      "Tensor data:\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([100, 20])\n",
      "torch.float64\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Convert to pytorch tensor\n",
    "dataT = torch.tensor( data ) \n",
    "\n",
    "# print out some information\n",
    "print('Numpy data:')\n",
    "print(type(data))\n",
    "print(data.shape) # numpy -> .shape\n",
    "print(data.dtype)\n",
    "print(' ')\n",
    "\n",
    "print('Tensor data:')\n",
    "print(type(dataT))\n",
    "print(dataT.size()) # torch -> .size(), .shape\n",
    "print(dataT.dtype)\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "WlSTQeZ2nDDR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Sometimes you need to convert data types\n",
    "\n",
    "dataT2 = torch.tensor( data ).float()\n",
    "print(dataT2.dtype)\n",
    "\n",
    "# \"long\" is for ints\n",
    "dataT3 = torch.tensor( data ).long()\n",
    "print(dataT3.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.6046, -0.4972,  0.6407,  ..., -0.5713,  1.0585, -1.2979],\n",
      "        [-0.6741, -0.3466,  0.2241,  ...,  0.4458, -1.5515,  2.3055],\n",
      "        [ 0.9924, -2.3596,  1.5630,  ...,  1.1902, -0.5177, -0.6143],\n",
      "        ...,\n",
      "        [ 1.7630,  0.8127, -0.0171,  ...,  0.3745, -1.7686,  0.2046],\n",
      "        [ 0.8156, -1.4926, -0.0838,  ...,  0.6181, -0.5963,  1.3386],\n",
      "        [ 0.5590,  1.5688,  0.6729,  ..., -0.2202,  0.3429,  0.4807]])\n",
      "tensor([[ 1,  0,  0,  ...,  0,  1, -1],\n",
      "        [ 0,  0,  0,  ...,  0, -1,  2],\n",
      "        [ 0, -2,  1,  ...,  1,  0,  0],\n",
      "        ...,\n",
      "        [ 1,  0,  0,  ...,  0, -1,  0],\n",
      "        [ 0, -1,  0,  ...,  0,  0,  1],\n",
      "        [ 0,  1,  0,  ...,  0,  0,  0]])\n"
     ]
    }
   ],
   "source": [
    "print(dataT2)\n",
    "print(dataT3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "u5fGd4h8mI8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.6046, -0.4972,  0.6407,  ..., -0.5713,  1.0585, -1.2979],\n",
       "         [-0.6741, -0.3466,  0.2241,  ...,  0.4458, -1.5515,  2.3055],\n",
       "         [ 0.9924, -2.3596,  1.5630,  ...,  1.1902, -0.5177, -0.6143],\n",
       "         ...,\n",
       "         [ 1.7630,  0.8127, -0.0171,  ...,  0.3745, -1.7686,  0.2046],\n",
       "         [ 0.8156, -1.4926, -0.0838,  ...,  0.6181, -0.5963,  1.3386],\n",
       "         [ 0.5590,  1.5688,  0.6729,  ..., -0.2202,  0.3429,  0.4807]],\n",
       "        dtype=torch.float64),)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert tensor into PyTorch Datasets\n",
    "\n",
    "# dataset = TensorDataset(data) # this creates ERROR: not a tensor!\n",
    "dataset = TensorDataset(dataT)\n",
    "\n",
    "# pytorch Dataset: a two-element tuple comprising data,labels\n",
    "# so far it only contains data\n",
    "dataset.tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "wpvxvxBloej3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 3., 3., 3., 3.,\n",
      "         3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
      "         3., 3., 3., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.,\n",
      "         4., 4., 4., 4., 4., 4., 4., 4., 4., 4.]])\n",
      "torch.Size([100, 20])\n",
      "torch.Size([100, 1])\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "# Let's try again with labels\n",
    "labels = torch.ceil(torch.linspace(.01,4,nObservations))\n",
    "\n",
    "# transform to an actual matrix (column vector)\n",
    "labels = labels.reshape(( len(labels),1 ))\n",
    "print( labels.T )\n",
    "\n",
    "# now make another dataset\n",
    "dataset = TensorDataset(dataT,labels)\n",
    "print( dataset.tensors[0].size() )\n",
    "print( dataset.tensors[1].size() )\n",
    "\n",
    "# for comparison\n",
    "# this is an ordered set, not a matrix like dataset.tensors[1]\n",
    "print( np.shape(np.random.randint(5,size=nObservations)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJ-JsNQGpIKT"
   },
   "source": [
    "# DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "5_kahYcanxBg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 20])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataloader object\n",
    "batchsize = 25\n",
    "dataloader = DataLoader(dataset,batch_size=batchsize)#,shuffle=True,drop_last=True)\n",
    "\n",
    "# dataset.tensors is where the full dataset is stored\n",
    "dataloader.dataset.tensors[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "xu7BF_OTqDj0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH INFO:\n",
      "torch.Size([25, 20])\n",
      "torch.Size([25, 1])\n",
      " \n",
      "BATCH INFO:\n",
      "torch.Size([25, 20])\n",
      "torch.Size([25, 1])\n",
      " \n",
      "BATCH INFO:\n",
      "torch.Size([25, 20])\n",
      "torch.Size([25, 1])\n",
      " \n",
      "BATCH INFO:\n",
      "torch.Size([25, 20])\n",
      "torch.Size([25, 1])\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# pytorch Dataloader: an iterable that breaks dataset into mini-batches\n",
    "\n",
    "for dat,labs in dataloader:\n",
    "  # sizes of each batch\n",
    "  print('BATCH INFO:')\n",
    "  print(dat.size()) # shape: 25 - batch size, 20 - # features\n",
    "  print(labs.size())\n",
    "  print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "oLkY18PZq-G3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1.]])\n",
      " \n",
      "tensor([[2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "         2., 2., 2., 2., 2., 2., 2.]])\n",
      " \n",
      "tensor([[3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
      "         3., 3., 3., 3., 3., 3., 3.]])\n",
      " \n",
      "tensor([[4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.,\n",
      "         4., 4., 4., 4., 4., 4., 4.]])\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# inspect the labels\n",
    "for dat,labs in dataloader:\n",
    "  print(labs.T)\n",
    "  print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "zyeJ6mjjre6p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 3., 2., 3., 1., 4., 3., 2., 4., 3., 1., 3., 4., 4., 4., 2., 1., 1.,\n",
      "         2., 3., 2., 2., 3., 1., 2.]])\n",
      " \n",
      "tensor([[3., 2., 4., 1., 3., 2., 3., 1., 2., 2., 4., 4., 3., 3., 2., 4., 1., 1.,\n",
      "         4., 4., 2., 1., 4., 4., 2.]])\n",
      " \n",
      "tensor([[3., 3., 2., 3., 1., 4., 1., 3., 3., 3., 2., 2., 2., 2., 2., 1., 1., 1.,\n",
      "         4., 1., 1., 4., 1., 4., 4.]])\n",
      " \n",
      "tensor([[2., 1., 3., 2., 3., 1., 4., 3., 1., 4., 1., 4., 3., 3., 4., 3., 1., 4.,\n",
      "         2., 4., 4., 2., 2., 3., 1.]])\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# try again with shuffling (shuffling occurs whenever u call for loop on dataloader)\n",
    "# dataloader = DataLoader(dataset,batch_size=batchsize,shuffle=True)\n",
    "\n",
    "for dat,labs in dataloader:\n",
    "  print(labs.T)\n",
    "  print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "S236TLLury42"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [3.],\n",
       "        [4.],\n",
       "        [1.],\n",
       "        [2.],\n",
       "        [4.],\n",
       "        [1.],\n",
       "        [4.],\n",
       "        [1.],\n",
       "        [3.],\n",
       "        [3.],\n",
       "        [4.],\n",
       "        [3.],\n",
       "        [3.],\n",
       "        [1.],\n",
       "        [2.],\n",
       "        [1.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get only one batch (e.g., for testing)\n",
    "\n",
    "dat,labs = next(iter(dataloader))\n",
    "\n",
    "labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMDTrf0kN4swdushiJqB9Kn",
   "collapsed_sections": [],
   "name": "DUDL_data_datasetLoader.ipynb",
   "provenance": [
    {
     "file_id": "1t1AgKE-GpPPUcjGZyTF_Ie1Q9XWA3xn-",
     "timestamp": 1618172332728
    },
    {
     "file_id": "1qKgZ8kVcqNgwtBzHbWq5yJH_HqI6DxWW",
     "timestamp": 1617803880910
    },
    {
     "file_id": "15cpyHkJ435B4MqbyGjAH1poN4nCy_DE4",
     "timestamp": 1617737766196
    },
    {
     "file_id": "1OLuWuaFu0hcFgkQ2hh5BqbRuqUZD7XcQ",
     "timestamp": 1617734878578
    },
    {
     "file_id": "1XvzVGJPTJifVh8OpZVB7ykLxyUqYwQ1j",
     "timestamp": 1617196833019
    },
    {
     "file_id": "1bv1_y32e3KEExFKKlPfC3rpw1JxmBr8H",
     "timestamp": 1617124341706
    },
    {
     "file_id": "1GMq8u7KyHB2AE7Teyls9gK1T01OduQSn",
     "timestamp": 1616697516760
    },
    {
     "file_id": "1Ui3kyHim-e0XLgDs2mkBxVlYg7TKYtcg",
     "timestamp": 1616615469755
    },
    {
     "file_id": "1YpHocGI4rApOxIBb1ZghCU5L-hFnv4CK",
     "timestamp": 1616608248670
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
